{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ded04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset, random_split, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111a906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/user/user1_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a5997d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label, **hyperparameters):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i], self.label[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b76f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02b50c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "  def __init__(self, n_users, n_movies, n_factors=50, embedding_dropout=0.02, hidden=10, dropouts=0.2):\n",
    "    super().__init__()\n",
    "            \n",
    "    self.u = nn.Embedding(n_users, n_factors)\n",
    "    self.m = nn.Embedding(n_movies, n_factors)\n",
    "    self.drop = nn.Dropout(embedding_dropout)\n",
    "    self.hidden = nn.Sequential(\n",
    "        nn.Linear(n_factors*2, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropouts),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropouts),\n",
    "        nn.Linear(32, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropouts),\n",
    "    )\n",
    "    self.fc = nn.Linear(16, 1)\n",
    "\n",
    "\n",
    "  def forward(self, users, movies, minmax=None):\n",
    "    features = torch.cat([self.u(users), self.m(movies)], dim=1)\n",
    "    x = self.drop(features)\n",
    "    x = self.hidden(x)\n",
    "    out = self.fc(x)\n",
    "    # if minmax is not None:\n",
    "    #     min_rating, max_rating = minmax\n",
    "    #     out = out*(max_rating - min_rating + 1) + min_rating - 0.5\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dea83c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_movies = 943, 1664\n",
    "model = EmbeddingNet(n_users=n_users, n_movies=n_movies, n_factors=150, hidden=[500, 500, 500], embedding_dropout=0.05, dropouts=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6630082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "batch_size = 1024\n",
    "minmax = (1.0,5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8b2526f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/user/user1_0.csv\")[[\"user\",\"movie\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c3f761b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"data/user/rating1_0.csv\")[[\"rating\"]].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0126e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.from_numpy(y_train).squeeze()\n",
    "d = torch.from_numpy(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "58cc8e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4527, 2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e773e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/user/user1_0.csv\")[[\"user\",\"movie\"]].to_numpy()\n",
    "y_train = pd.read_csv(\"data/user/rating1_0.csv\")[[\"rating\"]].to_numpy()\n",
    "\n",
    "X_train = torch.as_tensor(X_train)\n",
    "y_train = torch.as_tensor(y_train,dtype=torch.float).squeeze()\n",
    "\n",
    "\n",
    "X_test = pd.read_csv(\"data/test/test_u.csv\")[[\"user\",\"movie\"]].to_numpy()\n",
    "y_test = pd.read_csv(\"data/test/test_r.csv\")[[\"rating\"]].to_numpy()\n",
    "\n",
    "X_test = torch.as_tensor(X_test)\n",
    "y_test = torch.as_tensor(y_test,dtype=torch.float).squeeze()\n",
    "\n",
    "max_rating=5.0\n",
    "min_rating=1.0\n",
    "y_train = (y_train - min_rating)/(max_rating - min_rating)\n",
    "y_test = (y_test - min_rating)/(max_rating - min_rating)\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = MyDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "742e99f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(\"data/test/test_r.csv\")[[\"rating\"]].to_numpy()\n",
    "y_test = torch.from_numpy(y_test).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d791ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"data/user/rating1_0.csv\")[[\"rating\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "73306fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21081ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingNet(\n",
       "  (u): Embedding(943, 150)\n",
       "  (m): Embedding(1664, 150)\n",
       "  (drop): Dropout(p=0.05, inplace=False)\n",
       "  (hidden): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.05, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.05, inplace=False)\n",
       "    (6): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0e3ccce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_loader, model, criterion):\n",
    "  model.eval()\n",
    "  acc = 0\n",
    "  total_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "      for data, label in data_loader:\n",
    "        # label = label.type(torch.LongTensor)\n",
    "        outputs = model(data[:, 0], data[:, 1], minmax=minmax)\n",
    "        loss = criterion(outputs, label)\n",
    "        total_loss += loss.item()\n",
    "        _, pred_labels = torch.max(outputs, dim=1)\n",
    "        for pred_label, gt_label in zip(pred_labels.view(-1), label.view(-1)):\n",
    "            if pred_label == gt_label:\n",
    "                acc += 1\n",
    "  model.train()\n",
    "  return acc, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "51fe9954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([754])) that is different to the input size (torch.Size([754, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.175188479582574 0.14884249764674884\n",
      "0.13049255735120527 0.11464090911650969\n",
      "0.12469006659101381 0.10810966989102072\n",
      "0.11439814819308973 0.11131360083668976\n",
      "0.1106763080911234 0.11126433423194387\n",
      "0.1108109457539701 0.10622811427446402\n",
      "0.10908836599004065 0.10107422410664611\n",
      "0.10831618261621676 0.0996232364696629\n",
      "0.10683219543955882 0.10020241158656634\n",
      "0.10762548393989363 0.1008480726297545\n",
      "0.10757200570988133 0.10053315234399487\n",
      "0.10653879828397238 0.09942870833570046\n",
      "0.10566704347482811 0.09855196923166962\n",
      "0.1068372277726868 0.09868695824411712\n",
      "0.10578379326633515 0.09905991779048082\n",
      "0.10713041426462924 0.09867305621699081\n",
      "0.10708194982934424 0.09836833881160081\n",
      "0.1058070892947437 0.09851895775216274\n",
      "0.10531510204991837 0.09880288601399903\n",
      "0.10697233058085946 0.09765694483352401\n",
      "0.10575333467403047 0.09785822463729078\n",
      "0.10561057382107097 0.0979107825184538\n",
      "0.10660414614634244 0.09722078451541147\n",
      "0.10535805046834876 0.0979021873971524\n",
      "0.10570918631548383 0.09809208662364045\n",
      "0.10669740609888843 0.09715484649750031\n",
      "0.10524777226398553 0.09724886788049696\n",
      "0.10506686275306062 0.09711039704807782\n",
      "0.1047657249725389 0.09693576196729838\n",
      "0.10581472037458409 0.09645613323123668\n",
      "0.10441989279330527 0.09661233609275091\n",
      "0.10534515953864487 0.09639996726630086\n",
      "0.10411189748984392 0.09674822272603945\n",
      "0.10435227313419829 0.09583175031686858\n",
      "0.10559110007381924 0.09600875992234516\n",
      "0.10476869785788308 0.09596667122338695\n",
      "0.10487122364014696 0.09586257092811638\n",
      "0.10434929013699919 0.09568997749474008\n",
      "0.10526215300697982 0.09469478304909847\n",
      "0.10591133072172434 0.09545177203363019\n",
      "0.10520660690263799 0.0959870364266628\n",
      "0.10465264578436499 0.09482726438593123\n",
      "0.10333219763720196 0.09423364086399824\n",
      "0.10464034639817346 0.0947014979876152\n",
      "0.10360144936856724 0.09458540110076323\n",
      "0.10527470518954415 0.09407881389529918\n",
      "0.10454717745232166 0.09455450396599956\n",
      "0.10433155225817405 0.09400976978787927\n",
      "0.10479109898713189 0.09393973699663444\n",
      "0.1052751147196681 0.09443598587510578\n",
      "0.10380957156637001 0.09373166113942413\n",
      "0.10361622784452142 0.09291674155768086\n",
      "0.10410483435918776 0.09292686944500493\n",
      "0.10479228207415663 0.0937821054410791\n",
      "0.10372976880740298 0.09280182160250282\n",
      "0.10403091669977962 0.09173050998087035\n",
      "0.10407632061364452 0.09256836595602236\n",
      "0.10484615298120134 0.0925149196368402\n",
      "0.10278339356493418 0.09210867236107738\n",
      "0.10428749490632162 0.09194765923135617\n",
      "0.10464180419058997 0.09221835963824089\n",
      "0.10300222084647065 0.09158044813150389\n",
      "0.10273814975543873 0.09129959152359422\n",
      "0.10358811688786551 0.09126252429774676\n",
      "0.10395314136772249 0.09152589298657691\n",
      "0.10358790622422151 0.09095588079546256\n",
      "0.10427722463234913 0.09107184988804304\n",
      "0.10362179610595973 0.09066489476975849\n",
      "0.10333066569118277 0.0902069367281532\n",
      "0.10327921994400782 0.0909302255215353\n",
      "0.10485381776722477 0.09053660539112454\n",
      "0.10326229944012143 0.0908685674638662\n",
      "0.10348909654863786 0.08962139102855442\n",
      "0.10406366899784021 0.09056715970053716\n",
      "0.10450659352263157 0.08990524429734516\n",
      "0.10528408393497522 0.08945581403634732\n",
      "0.10408885594311734 0.09069983464186505\n",
      "0.10467473007549322 0.0888333113047639\n",
      "0.10332568728794767 0.08980305632473592\n",
      "0.10329198953145277 0.08876145189719549\n",
      "0.10318936768656722 0.08926195930932446\n",
      "0.10473466135424864 0.08952178572460545\n",
      "0.10469547960177304 0.08878341032007155\n",
      "0.10338714377148567 0.08951796107928277\n",
      "0.10368819897185895 0.08831201092290543\n",
      "0.10345498420609157 0.08851746355399205\n",
      "0.1035150064915412 0.08841066733525772\n",
      "0.10320036264347508 0.08807072615551734\n",
      "0.10288164034726105 0.0884828619158256\n",
      "0.10429232163173303 0.08815114165739406\n",
      "0.10302728476417967 0.08783826607997822\n",
      "0.10465464287571015 0.08840844509235715\n",
      "0.10410273783460262 0.08824785207673802\n",
      "0.10425821265980506 0.08685636223857118\n",
      "0.10330058292281899 0.08842874754634998\n",
      "0.10265713862980969 0.08725869839743841\n",
      "0.10286287442985317 0.08750033211205883\n",
      "0.10357075651829042 0.08745229141403703\n",
      "0.10394131723871182 0.08751353700995565\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "  running_loss = 0.0\n",
    "  acc = 0\n",
    "  for i, (data, label) in enumerate(train_loader):\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "      # label = label.type(torch.LongTensor)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data[:, 0], data[:, 1], minmax=minmax)\n",
    "      _, pred_labels = torch.max(outputs, dim=1)\n",
    "      for pred_label, gt_label in zip(pred_labels.view(-1), label.view(-1)):\n",
    "        if pred_label + 1 == gt_label:\n",
    "          acc += 1\n",
    "      loss = criterion(outputs, label)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "  test_acc, test_loss = test(test_loader, model, criterion)\n",
    "  train_loss.append(running_loss * batch_size / len(X_train))\n",
    "  val_loss.append(test_loss * batch_size / len(X_test))\n",
    "  print(running_loss * batch_size / len(X_train), test_loss * batch_size / len(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3fa9f7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-macosx_10_14_x86_64.whl (241.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorflow) (4.3.0)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp39-cp39-macosx_10_9_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorflow) (1.50.0)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorflow) (1.21.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: packaging in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorflow) (3.19.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/dxshi/opt/anaconda3/envs/pysyft/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, keras, flatbuffers, tensorflow-io-gcs-filesystem, tensorflow-estimator, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorboard, tensorflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.11.0\n",
      "    Uninstalling tensorboard-2.11.0:\n",
      "      Successfully uninstalled tensorboard-2.11.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-22.10.26 gast-0.4.0 google-pasta-0.2.0 h5py-3.7.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 opt-einsum-3.3.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2c3285b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-34a8415f3834d931\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-34a8415f3834d931\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir training_logs/127.0.0.1:56428/experiment_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ca42de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebddb26a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
